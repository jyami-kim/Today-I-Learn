# 3. 저장소와 검색

### 데이터 베이스를 강력하게 만드는 데이터 구조

많은 데이터베이스는 내부적으로 추가 전용(append-only) 데이터 파일인 로그(Log)를 사용한다

- 로그 : 연속된 추가 전용 레코드 (사람이 읽을 수 있는 형식일 필요는 없다)

색인(index) : 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위한 데이터 구조

- 기본데이터(primary data)에서 파생된 추가적인 구조
- 데이터베이스의 내용에는 영향을 미치지 않으나 질의 성능에만 영향을 준다
- 어떤 종류의 색인이어도 대개 쓰기 속도를 느리게 만든다 : 데이터를 쓸 때마다 매번 색인도 갱신해야하기 때문



### 해시 색인

키-값 데이터를 색인한다

사전타입(dictionary type)과 매우 유사함 보통 해시맵으로 구현한다

키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시맵을 유지하는 전략

각 키의 값이 자주 갱신되는 상황에 매우 적합하다

파일에 항상 추가만 하면 결국 디스크 공간이 부족해진다 > 특정 크기의 **세그먼트(segment)** 로 로그를 나누는 방식이 좋은 해결책이다

- 특정 크기에 도달 : 새로운 세그먼트 파일에 이후 쓰기를 수행 > 세그먼트 파일들에 대해 컴팩션(compaction) 수행한다.
- 컴팩션 : 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것



구현시 중요한 문제

- 파일 형식 : CSV는 적합하지 않다. 바이너리가 더 빠르고 간단
- 레코드 삭제 : 삭제가 일어나면 실제 레코드 삭제는 안일어나고 톰스톤을 달아줘서 접근을 못하게 막는다
- 고장 (crash) 복구 : 세그먼트 파일이 크면 해시맵 복원은 오랜 시간이 걸릴 수 있고 서버 재시작을 고통스럽게함 > 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게, 스냅숏을 디스크에 저장해 복구 속도를 높인다.
- 부분적으로 레코드 쓰기 : 체크섬 포함 (로그의 손상 부분 탐지)
- 동시성 제어 : 데이터 파일 세그먼트는 추가 전용이거나 불변이므로, 다중 스레드로 동시에 읽기를 할 수 있다. : 쓰기시 하나의 쓰기 스레드만 사용

추가 전용 로그의 설계

- 추가와 세그먼트 병합은 순차적 쓰기라서 무작위 쓰기보다 훨씬 빠르다
- 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함께 나누어서 동시성, 고장 복구가 훨씬 간단하다
- 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다

해시 테이블 색인 제약상황

- 메모레이 저장해야해서 키가 너무 많으면 문제가 많다. 해시 충돌 해소를 위한 성가진 로직이 필요하다
- 해시테이블은 범위 질의(range query)에 효율적이지 않다.



### SS테이블과 LSM트리

SST : SS테이블 : 정렬된 문자열 테이블 : Sorted String Table : 키-값 쌍을 **키로 정렬** 

- 각 키는 병합된 세그먼트 파일 내에 한번만 나타나야한다 (컴팩션 과정이 이를 이미 보장한다)

1. 다중 세그먼트가 동일한 키를 포함하는 경우 가장 최근 세그먼트의 값을 유지하고 오래된 세그먼트의 값을 버린다

2. 파일에서 특정키를 찾기위해 메모리에 모든 키의 색인을 유지할 필요가 없다. (두 키 사이에 있다는 사실만 알면된다 )  : 메모리에는 모든 키에 대한 해시맵을 다 알필요 없이, 희소색인(sparse index)만 메모리에 관리하고 해당 범위만 보고 정렬된 값을 찾는다.

   일부 키에 대한 오프셋을 알려주는 인메모리 색인은 여전히 필요하다. 세그먼트 파일 내 수 킬로바이트당 키 하나로 충분하다

3. 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다.



저장소 엔진을 만든다면

- 쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(레드블랙트리)에 추가한다. 이 인메모리 트리를 멤테이블(memtable) 이라고도 한다
- 멤테이블이 임계값보다 커지면 SS테이블 파일로 디스크에 기록한다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾는다 그다음 최신 세그먼트, 그다음은 두번째 오래된 세그먼트,,
- 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다 (백그라운드 수행)



데이터 베이스가가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실된다 > 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크상에 유지한다 (멤테이블을 복원할 대만 필요)



### SS테이블에서 LSM 트리 만들기

알고리즘 : 레벨DB(LevelDB) + 록스 DB(RocksDB) + 키-값 저장소 엔진 라이브러리

LSM Tree = log (append only) + membtable (색인) + sstable (디스크 별도 관리)

로그 구조화 병합 트리(Log-Structured Merge-Tree) = LSM 트리 

- LSM 저장소 엔진 : 정렬된 파일 병합과 컴팩션 원리를 기반으로하는 저장소 엔진



#### 성능 최적화

블룸 필터(Bloom Filter) : 존재 여부를 확인하는 자료구조 - 값이 있나 없나를 알 수 있는 

- 집합 내용을 근사한 메모리 효율적 데이터 구조.
- 블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기를 많이 절약할 수 있다.

SS 테이블 압축 병합 순서 시기 결정하는 전략

- 크기 계층 (size-tiered) : 상대적으로 좀더 새롭고 작은 SS 테이블을 상대적으로 오래됐고 큰 SS 테이블에 연이어 병합
- 레벨 컴팩션 (leveled compaction) : 키 범위를 더 작은 SS테이블로 나누고, 오래된 데이터는 개별 레벨로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용한다.
  - leveled compaction 설명 : https://meeeejin.gitbooks.io/rocksdb-wiki-kr/content/leveled-compaction.html 
  - 두개 차이점 : https://docs.scylladb.com/architecture/compaction/compaction-strategies/



### B트리

- 로그 구조화 색인 : 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다
- B 트리 : 전통적으로 4KB 크기의 고정크기 블록이나 페이지로 나누고, 한번에 하나의 페이지에 읽기 또는 쓰기를 한다

리프 페이지(leaf page) : 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다. root에서 내려오면 이 페이지에 도달한다

분기 계수 (branching facotr) : B트리의 한 페이지에서 하위 페이지를 참조하는 수

이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다: n개의 키를 가진 B트리는 깊이가 항상 O(logn) 이다



#### 신뢰할 수 있는 B트리

기본 쓰기 동작 : 새로운 데이터를 디스크 상의 페이지에 덮어쓴다.

- 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전히 남는다 (페이지 참조는 같다. 덮어쓰기를 해도 페이지 위치는 변경하지 않는다.)

페이지를 덮어쓰는 일은 실제 하드웨어 동작이다

- HDD: 실제로 덮어쓴다 (적합한 섹터에 새로운 데이터를 덮어씀)
- SSD: SSD가 저장소 칩의 상당한 블록을 한번에 지우고 다시 쓰기를 해야해서 좀더 복잡한다 (아예 새로운 B트리를 새로 생성해야함)

일부 페이지만 기록하고 데이터베이스가 고장나면 색인이 훼손되어 매우 위험한 동작이다 : 고아페이지(orphan page)가 생성될 수 있다 : 어떤 페이지와도 부모 관계가 없는 페이지

- 디스크상에 쓰기전 로그**(write-ahead log, WAL)(재실행로그(redo log))** : 데이터베이스 스스로 복구를 할 대 필요한 데이터 구조 -> 데이터 베이스가 고장 이후 복구될 때 일관성 있는 상태로 B 트레 복원에 사용한다

같은 자리의 페이지 갱신 작업 > 동시성 제어 필요 > **래치 (latch)(가벼운 잠금(lock))** 으로 데이터 구조 보호



#### B트리 최적화

- WAL 유지 대신 일부데이터베이스는 쓰기 시 복사 방식(copy-on-write scheme)을 사용한다. 
- 페이지에 전체 키를 저장하는게 아니라 키를 축약해 쓰면 공간 절약 (키가 키 범위 사이의 경계 역할)
- 페이지는 디스크상 어디에나 위치할 수 있다. leaf 페이지를 디스크상에 연속된 순서로 나타나게끔 트리 배치하려 시도함. 하지만 트리가 커지면 순서 유지가 어렵다
  - LSM 트리 : 병합하는 고정에서 저장소의 큰 세그먼트를 한번에 다시쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 쉽다
- 트리에 포인터 추가 : 각 리프 페이지가 양쪽 형제 페이지 참조를 가진다
- 프랙탈트리(fractal tree) : 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌린다



#### B트리와 LSM 트리 비교

- B 트리 : 읽기에서 더 빠르다

- LSM 트리 : 쓰기에서 더 빠름

  읽기가 느린이유 : 각 컴팩션 단계에 있는 데이터구조 SS 테이블을 확인해야함



#### LSM 트리의 장점

B트리 색인

- 데이터 조각을 최소한 두번 기록한다 (쓰기전 로그 한번, 트리페이지에 한번)
- 해당 페이지내 몇 바이트만 바뀌어도 한번에 전체 페이지를 기록

로그  구조화 색인

- SS 테이블의 반복된 컴팩션, 병합때문에 여러번 데이터를 다시 쓴다
- 쓰기증폭(write amplification) : DB쓰기 한번이 DB 수명 동안 디스크에 여러번의 쓰기를 야기하는 효과 [SSD 수명다할 때까지 블록 덮어쓰기 횟수가 제한]

LSM 트리

- B 트리보다 쓰기 처리량을 높게 유지가 가능하다
- 상대적으로 쓰기 증폭이 더 낮고 트리에서 여러페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS테이블 파일을 쓰기 때문이다
- 압축률이 더 좋다 : B트리는 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다.



#### LSM 트리의 단점

- 컴팩션 과정이 때로는 진행 중인 읽기의 성능에 영향을 준다.

  - 비싼 컴팩션 연산이 끝날때까지 요청 대기 상황이 발생하기 쉽다

- 높은 쓰기 처리량에서 컴팩션 문제가 발생한다 : 데이터 베이스가 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다

  - 초기 쓰기(로깅(logging)과 멤테이블을 디스크로 방출(flushing))와 백그라운드 수행 컴팩션 스레드가 대역폭 공유

- 쓰기 처리량이 높음에도 컴팩션 설정을 주의깊게 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없다.

- 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다 (B트리는 각 키가 색인의 한 곳에만 존재)

  

### 기타 색인구조

보조 색인(secondary index)을 사용하는 방식도 일반적이다.

- 효율적인 조인을 수행하는데 결정적 역할을 한다
- 키-값 색인에서 쉽게 생성한다
- 기본키 색인과의 차이점 : 키가 고유하지 않다
- 같은 키를 가진 많은 로우가 있을 수 있다 : 로우 식별자 목록을 만드는 방법 / 로우 식별자를 추가해 각 키를 고유하게 만드는 방법



#### 색인안에 값 저장하기

색인에서 키는 질의가 검색하는 대상

색인에서 값은 두가지중하나

- 실제 로우(문서, 정점)

- 다른 곳에 저장된 로우를 가리키는 참조 : **힙파일(heap file)** : 특정 순서 없이 데이터 저장

  여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있다. (위치만 참조하고, 실제 데이터는 일정한 곳에 유지)

힙파일 효율적이다

- 새로운 값이 이전 값보다 많은 공간을 필요로 하지 않을 때 : 레코드를 제자리에 덮어씀
- 많은 공간을 필요로 할 때 : 힙에서 충분한 공간이 있는 새로운 곳으로 위치를 이동 (모든 색인이 새로운 힙 위치를 가리키게하거나 / 전방향 포인터)
- **클러스터드 색인 (clustered index)** : 어떤경우에는 색인 안에 바로 색인된 로우를 저장하는 편이 바람직하다
  - MySQL 이노DB 저장소 엔진 : 기본키가 클러스터드 색인 / 보조 색인은 기본키 참조

클러스터드 색인(색인안에 모든 로우 데이터 저장)과 비클러스터드 색인(색인안에 데이터의 참조만 저장)의 절충안

- 커버링 색인(covering index)(포괄열이 있는 색인(index with included column)) : 색인 안에 테이블의 칼럼 일부를 저장



#### 다중 칼럼 색인

테이블의 다중 칼럼에 동시에 질의를 해야할 경우

**결합색인(concatenated index)** : 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합한다. (성, 이름)

다차원 색인 : 여러 칼럼에 질의하는 일반적 방법 (지리 공간 데이터)

- 이차원 위치를 공간 채움 곡선(space-filling curve)을 이용해 단일 숫자로 변환한 다음 일반 B 트리 색인을 사용한다.
- 전문 공간 색인(specialized spatial index)  > 일반화된 검색트리(Generalized Search Tree) 색인 기능을 사용했다. : R 트리



#### 전문 검색과 퍼지 색인

철자가 틀린 단어와 같이 유사한 키에 대한 검색 => 애매모호한(fuzzy) 질의에는 다른 기술이 필요

전문 검색 엔진 : 특정 단어 검색시 동의어로 질의 확장함. 언어학적 텍스트 분석 / 특정 편집거리내 단어 검색 등

퍼지 검색 기술은 문서 분류, 머신러닝 방향으로 진행중



#### 모든 것을 메모리에 보관

모두 디스크 한계에 대한 해결책이었다. (디스크는 지속성이 있다 / 램보다 기가바이트당 가격이 더 저렴하다)

인메모리 데이터베이스 개발 : 램이 점점 저렴해져서 

- 인메모리 데이터베이스는 지속성을 목표로한다 : 배터링 전원 공급 RAM과 같은 특수 하드웨어를 사용하거나, 로그 기록하거나, 스냅숏 기록 등등

인메모리 데이터베이스의 성능 장점

- 충분한 메모리를 가진 경우에는 디스크에서 읽을 필요가 없다
- 다양한 데이터 구조를 같은 인터페이스로 제공
- 안티캐싱(anti-caching) 접근방식 : 메모리가 충분하지 않을대 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 내보내고 나중에 다시 접근할 때 메모리에 적재하는 방식



### 트랜잭션 처리나 분석

**커머셜 트랜잭션(commercial transaction)(상거래)**

트랜잭션 : 논리적 단위 형태의 읽기와 쓰기 그룹

**온라인 트랜잭션 처리(online transaction processing, OLTP)** : 애플리케이션의 대화식 접근 패턴

**온라인 분석 처리(online analytic processing,, OLAP)** : 비즈니스 분석가가 작성하며, 회사 경영진이 더 나은 의사결정을 하게끔 돕는 보고서(비즈니스 인텔리전스(business intelligence)

![3-1](../../Today-I-Learn/resource/data applicatin design/3-1.png)

데이터 웨어하우스(data warhouse) : 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터 베이스

ELT(Extract-Transform-Load) : OTLP 데이터베이스에서 추출(extract)하고 분석 친화적인 스키마로 변환(transform)하고 정리한다음 데이터 웨어하우스에 적재(load)



### 데이터 웨어하우징

#### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

SQL 질의를 생성하고, 결과를 시각화하고 분석가가(드릴다운(drilldown), 슬라이싱(slicing), 다이싱(dicin))  데이터를 탐색할 수 있게 해주는 그래픽 데이터 분석도구



#### 분석용 스키마 : 별 모양 스키마와 눈꽃송이 모양 스키마

**별모양 스키마(star schema)**(차원 모델링(dimensional modeling)) : 정형화된 방식 - 데이터 모델의 다양성이 훨씬 적다.

스키마 중심에 사실테이블(fact table)이 있다.

fact를 중심으로 dim 을 여러개 가져와서 분석한다.

사실테이블의 다른 칼럼 : 차원테이블(dimmension table) : 다른 테이블을 가리키는 외래 키 참조

- 사실테이블의 각 로우 : 이벤트 : 분석의 유연성 극대화
- 차원 : 이벤트의 속성 : 누가(who), 언제(when), 어디서(where), 무엇을(what), 어떻게(how), 왜(why)



**눈꽃송이 모양 스키마(snowflake schema)** : 차원이 하위 차원으로 더 세분화된다

>  dim_product 테이블의 각 로우는 dim_product 테이블에 문자열로 브랜드와 범주를 저장하는 대신 외래키 참조가 된다.



### 칼럼 지향 저장소

질의의 효율적 시행

대부분의 OLTP 데이터베이스 : 로우 지향 방식으로 데이터 배치함. 

칼럼지향 저장소 : 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 칼럼별로 모든 값을 함께 저장한다.

칼럼 파일에 포함된 로우가 모두 같은 순서인 점에 의존한다.



### 칼럼 압축

#### **비트맵 부호화(bitmap encoding)**

> product_sk = 29; 9,1 : 0이 9개, 1이 1개, 나머지는 0

보통 칼럼에서 고유값의 수는 로우 수에 비해 적다.

n개의 고유 값을 가진 칼럼을 가져와 n개의 개별 비트맵으로 변환할 수 있다. 
각 고유값 하나가 하나의 비트맵이고, 각 로우는 한 비트를 가진다.

비트맵을 적재하고, N개의 비트맵 비트 OR을 계산한다.



#### 메모리 대역폭과 벡터화 처리

분석용 DB 개발자

- 메인 메모리에서 CPU 캐시로가는 대역폭을 효율적으로 사용
- CPU 명령처리 파이프라인에서 분기 예측 실패(branch misprediction)와 버블(bubble)을 피하며
- 최신 CPU에서 단일 명령 다중 데이터(single-instruction-multi-data, SIMD) 명령을 사용하게 신경써야함.

칼럼 저장소 배치 : 디스크로부터 적재할 데이터 양 줄이기 / CPU 주기 효율적으로 사용하기

**벡터화처리(vectorized processing)** : 비트 AND, OR 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계할 수 있다.



#### 칼럼 저장소의 순서 정렬

칼럼저장소에서 로우가 저장되는 순서가 반드시 중요하지는 않다. (삽입된 순서로 저장하는 방식이 가장 쉽다.)

데이터베이스 관리자는 공통 질의에 대한 



#### 다양한 순서 정렬

데이터를 여러 장비에 복제해두는 작업이 필요하다. 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면, 질의 처리시 가장 질의 패턴에 적합한 버전을 사용할 수 있다.



#### 칼럼 지향 저장소에 쓰기

B트리 사용과 같이 제자리 갱신(update-in-place) 접근 방식은 압축된 칼럼에서는 불가능하다 : 모든 칼럼파일 재작성

LSM 트리는 가능하다 : 충분한 쓰기를 모으면 디스크의 칼럼파일에 병합하고 대량으로 새로운 파일에 기록한다. 

질의는 칼럼데이터와 메모리의 최근 쓰기를 모두 조사해 두 가지를 결합해야한다.



#### 집계 : 데이터 큐브와 구체화뷰

칼럼 저장소 : 즉석 분석 질의에 대해 상당히 빠르기 때문에 급속하게 인기를 얻고있다.

구체화 집계(materialized aggregate) : 동일한 집계를 많은 다양한 질의에서 사용한다면 매번 원시 데이터를 처리하는건 낭비다. 질의가 자주사용하는 일부 카운트(count)나 합(sum)을 캐시

구체화 뷰(materialized view) : 카운트, 합 캐시를 대개 표준 뷰로 정의한다. 

- 갱신 쓰기 비용이 비싸서 OLTP 에서는 구체화 뷰를 자주 사용하지 않음
- 데이터 웨어하우스는 읽기 비중이 크기 때문에 구체화 뷰를 사용하는 전략은 합리적이다

데이터 큐브(data cube) = OLAP 큐브 : 일반화된 구체화 뷰의 특별사례



























